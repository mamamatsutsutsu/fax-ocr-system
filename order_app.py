import streamlit as st
import google.generativeai as genai
from PIL import Image, ImageEnhance, ImageFilter
import pandas as pd
import json
import re
import time
import io
from datetime import datetime
import fitz  # PyMuPDF

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import mm


# -----------------------------
# Helpers: Image preprocessing
# -----------------------------
def preprocess_image(img: Image.Image, contrast: float, sharpen: bool, binarize: bool) -> Image.Image:
    # Grayscale
    x = img.convert("L")
    # Contrast
    x = ImageEnhance.Contrast(x).enhance(contrast)
    # Sharpen
    if sharpen:
        x = x.filter(ImageFilter.SHARPEN)
    # Binarize (simple threshold)
    if binarize:
        x = x.point(lambda p: 255 if p > 160 else 0)
    return x


# -----------------------------
# Helpers: PDF -> images
# -----------------------------
def pdf_to_images(file_bytes: bytes, max_pages: int, dpi: int) -> tuple[list[Image.Image], int, int]:
    doc = fitz.open(stream=file_bytes, filetype="pdf")
    total_pages = len(doc)
    use_pages = min(total_pages, max_pages)

    images: list[Image.Image] = []
    for i in range(use_pages):
        page = doc.load_page(i)
        pix = page.get_pixmap(dpi=dpi)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)

    return images, total_pages, use_pages


# -----------------------------
# Helpers: robust JSON extract
# -----------------------------
_JSON_ARRAY_RE = re.compile(r"\[[\s\S]*\]")

def safe_json_extract(text: str):
    """
    Returns list[dict] or None
    """
    if not text:
        return None

    # 1) try direct bracket slice (fast)
    try:
        s = text.find("[")
        e = text.rfind("]") + 1
        if s != -1 and e != -1 and e > s:
            return json.loads(text[s:e])
    except Exception:
        pass

    # 2) remove code fences and retry
    try:
        cleaned = text.replace("```json", "").replace("```", "").strip()
        s = cleaned.find("[")
        e = cleaned.rfind("]") + 1
        if s != -1 and e != -1 and e > s:
            return json.loads(cleaned[s:e])
    except Exception:
        pass

    # 3) regex capture largest array
    try:
        m = _JSON_ARRAY_RE.search(text)
        if m:
            return json.loads(m.group(0))
    except Exception:
        pass

    return None


# -----------------------------
# Helpers: normalize rows
# -----------------------------
REQUIRED_KEYS = ["æ³¨æ–‡æ—¥", "é¡§å®¢å", "å“å", "è¦æ ¼ãƒ»ã‚µã‚¤ã‚º", "æ•°é‡", "å˜ä½", "å‚™è€ƒ"]

def normalize_rows(rows, meta: dict):
    out = []
    if not isinstance(rows, list):
        return out
    for r in rows:
        if not isinstance(r, dict):
            continue
        item = {k: str(r.get(k, "") if r.get(k, "") is not None else "") for k in REQUIRED_KEYS}
        # meta
        item.update(meta)
        out.append(item)
    return out


# -----------------------------
# PDF output
# -----------------------------
def create_simple_pdf(df: pd.DataFrame) -> io.BytesIO:
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=A4)

    y = 285 * mm
    c.setFont("Helvetica", 14)
    c.drawString(20 * mm, y, "Delivery Slip / Shipping Instruction")
    y -= 12 * mm

    c.setFont("Helvetica", 9)
    c.drawString(20 * mm, y, f"Issued: {datetime.now().strftime('%Y-%m-%d')}")
    y -= 10 * mm

    c.setFont("Helvetica", 9)
    headers = ["æ³¨æ–‡æ—¥", "é¡§å®¢å", "å“å", "è¦æ ¼ãƒ»ã‚µã‚¤ã‚º", "æ•°é‡", "å˜ä½", "å‚™è€ƒ"]
    colx = [20, 45, 85, 125, 155, 168, 180]
    for i, h in enumerate(headers):
        c.drawString(colx[i] * mm, y, h)
    y -= 6 * mm
    c.line(15 * mm, y, 195 * mm, y)
    y -= 8 * mm

    for _, row in df.iterrows():
        if y < 20 * mm:
            c.showPage()
            y = 285 * mm
            c.setFont("Helvetica", 9)

        c.drawString(20 * mm, y, str(row.get("æ³¨æ–‡æ—¥", ""))[:10])
        c.drawString(45 * mm, y, str(row.get("é¡§å®¢å", ""))[:10])
        c.drawString(85 * mm, y, str(row.get("å“å", ""))[:14])
        c.drawString(125 * mm, y, str(row.get("è¦æ ¼ãƒ»ã‚µã‚¤ã‚º", ""))[:12])
        c.drawString(155 * mm, y, str(row.get("æ•°é‡", ""))[:6])
        c.drawString(168 * mm, y, str(row.get("å˜ä½", ""))[:6])
        c.drawString(180 * mm, y, str(row.get("å‚™è€ƒ", ""))[:10])
        y -= 8 * mm

    c.save()
    buf.seek(0)
    return buf


# -----------------------------
# Gemini model (cached)
# -----------------------------
@st.cache_resource
def get_model(api_key: str, temperature: float, max_output_tokens: int):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "temperature": temperature,
            "max_output_tokens": max_output_tokens,
        },
    )


# -----------------------------
# Prompt (accuracy boosted)
# -----------------------------
def build_prompt() -> str:
    # é‡è¦ï¼šèª¬æ˜æ–‡ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç¦æ­¢ã—ã€ã€ŒJSONé…åˆ—ã®ã¿ã€ã‚’å¼·åˆ¶
    return """
ã‚ãªãŸã¯ã€ŒFAXå—æ³¨æ›¸ã€ã‹ã‚‰å—æ³¨ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æŠ½å‡ºã™ã‚‹å°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
å¿…ãšã€JSONé…åˆ—ã€‘ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å‰ç½®ã/èª¬æ˜/ã‚³ãƒ¡ãƒ³ãƒˆ/ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ã§ã™ã€‚
å‡ºåŠ›ã¯å¿…ãš `[` ã§å§‹ã¾ã‚Š `]` ã§çµ‚ã‚ã‚‹ã“ã¨ã€‚

ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
- H/W/C/æ ªç«‹/å˜æœ¨/é«˜ã•/è‘‰å¼µ/å¹¹å‘¨ ãªã©ã®è¦æ ¼æƒ…å ±ã¯ã€Œè¦æ ¼ãƒ»ã‚µã‚¤ã‚ºã€ã«é›†ç´„ã™ã‚‹
- ç¾å ´ç›´é€ãƒ»ç´æœŸãƒ»é…é”æŒ‡å®šãƒ»æ™‚é–“å¸¯ãƒ»ä»£å¼•ããƒ»è‡³æ€¥ãªã©ã¯ã€Œå‚™è€ƒã€ã«å…¥ã‚Œã‚‹
- æ•°é‡ã¯åŠè§’æ•°å­—ã®ã¿ï¼ˆä¾‹: "3"ï¼‰
- ä¸æ˜ãªé …ç›®ã¯ç©ºæ–‡å­— "" ã¨ã™ã‚‹
- 1æšã«è¤‡æ•°è¡Œã®æ³¨æ–‡ãŒã‚ã‚Œã°è¤‡æ•°è¦ç´ ã§è¿”ã™

ã€JSONã‚­ãƒ¼ï¼ˆå›ºå®šãƒ»é †åºã¯å•ã‚ãªã„ï¼‰ã€‘
[
  {
    "æ³¨æ–‡æ—¥":"YYYY/MM/DD",
    "é¡§å®¢å":"",
    "å“å":"",
    "è¦æ ¼ãƒ»ã‚µã‚¤ã‚º":"",
    "æ•°é‡":"",
    "å˜ä½":"",
    "å‚™è€ƒ":""
  }
]
"""


# -----------------------------
# Main
# -----------------------------
def run():
    api_key = st.secrets.get("GOOGLE_API_KEY")
    if not api_key:
        st.error("âš  GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info('Streamlit Cloud â†’ Manage app â†’ Settings â†’ Secrets ã« `GOOGLE_API_KEY="..."` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚')
        st.stop()

    # Session state init
    if "orders" not in st.session_state:
        st.session_state.orders = pd.DataFrame()
    if "logs" not in st.session_state:
        st.session_state.logs = []

    # ---------------- UI header ----------------
    st.title("ğŸŒ² FAX Order Intelligence")
    st.caption("PDF/Images â†’ Preprocess â†’ Gemini Extraction â†’ Editable Orders â†’ Export")

    with st.expander("âš™ï¸ Processing Settings", expanded=True):
        colA, colB, colC = st.columns(3)

        with colA:
            max_pages = st.slider("PDF page limit", min_value=1, max_value=20, value=5, step=1)
            dpi = st.slider("PDF render DPI", min_value=120, max_value=300, value=220, step=10)
        with colB:
            # ã‚³ã‚¹ãƒˆåˆ¶å¾¡ï¼šä½æ¸©åº¦ + å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™
            temperature = st.slider("Temperature (stability)", min_value=0.0, max_value=1.0, value=0.1, step=0.05)
            max_output_tokens = st.slider("Max output tokens (cost control)", min_value=200, max_value=2500, value=900, step=100)
        with colC:
            contrast = st.slider("Preprocess contrast", min_value=1.0, max_value=3.0, value=2.2, step=0.1)
            sharpen = st.checkbox("Sharpen", value=True)
            binarize = st.checkbox("Binarize", value=False)

        retry_json = st.checkbox("Auto-retry if JSON parse fails (1 retry)", value=True)
        show_raw = st.checkbox("Debug: show raw model response", value=False)

    model = get_model(api_key, temperature, max_output_tokens)
    prompt = build_prompt()

    # ---------------- Upload ----------------
    uploaded_files = st.file_uploader(
        "Upload FAX files (JPG/PNG/JPEG/PDF)",
        type=["jpg", "png", "jpeg", "pdf"],
        accept_multiple_files=True,
    )

    analyze_clicked = st.button("ğŸš€ Start AI Analysis", type="primary", use_container_width=True)

    if analyze_clicked:
        if not uploaded_files:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # Pre-count tasks for progress
        total_tasks = 0
        file_plan = []  # list of dict describing each unit

        for uf in uploaded_files:
            if uf.type == "application/pdf":
                b = uf.getvalue()
                try:
                    doc = fitz.open(stream=b, filetype="pdf")
                    total_pages = len(doc)
                    use_pages = min(total_pages, max_pages)
                    total_tasks += use_pages
                    file_plan.append({"name": uf.name, "type": "pdf", "bytes": b, "total_pages": total_pages, "use_pages": use_pages})
                except Exception as e:
                    st.session_state.logs.append({
                        "timestamp": datetime.now().isoformat(),
                        "status": "pdf_open_error",
                        "file": uf.name,
                        "detail": str(e),
                    })
            else:
                total_tasks += 1
                file_plan.append({"name": uf.name, "type": "img", "file": uf})

        if total_tasks == 0:
            st.error("è§£æå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆPDFãŒå£Šã‚Œã¦ã„ã‚‹/ãƒšãƒ¼ã‚¸åˆ¶é™/ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å•é¡Œã®å¯èƒ½æ€§ï¼‰ã€‚")
            st.stop()

        prog = st.progress(0)
        status = st.empty()

        results_all = []
        completed = 0

        for fp in file_plan:
            if fp["type"] == "pdf":
                images, total_pages, use_pages = pdf_to_images(fp["bytes"], max_pages=use_pages, dpi=dpi)
                for page_idx, img in enumerate(images, start=1):
                    status.text(f"Processing: {fp['name']} (page {page_idx}/{use_pages})  |  {completed+1}/{total_tasks}")

                    t0 = time.time()
                    try:
                        pre = preprocess_image(img, contrast=contrast, sharpen=sharpen, binarize=binarize)

                        resp = model.generate_content([prompt, pre])
                        raw = getattr(resp, "text", "") or ""

                        rows = safe_json_extract(raw)

                        # retry once with stricter instruction
                        if rows is None and retry_json:
                            reprompt = prompt + "\n\nã€å†å‡ºåŠ›æŒ‡ç¤ºã€‘å¿…ãšJSONé…åˆ—ã®ã¿ã‚’è¿”ã™ã€‚æ–‡å­—åˆ—èª¬æ˜ã¯ç¦æ­¢ã€‚"
                            resp2 = model.generate_content([reprompt, pre])
                            raw2 = getattr(resp2, "text", "") or ""
                            rows = safe_json_extract(raw2)
                            if show_raw:
                                st.write(f"RAW (retry) {fp['name']} p{page_idx}:")
                                st.code(raw2)

                        if show_raw:
                            st.write(f"RAW {fp['name']} p{page_idx}:")
                            st.code(raw)

                        meta = {
                            "å…ƒãƒ•ã‚¡ã‚¤ãƒ«": fp["name"],
                            "ãƒšãƒ¼ã‚¸": str(page_idx),
                        }
                        norm = normalize_rows(rows, meta=meta)
                        if norm:
                            results_all.extend(norm)
                            st.session_state.logs.append({
                                "timestamp": datetime.now().isoformat(),
                                "status": "success",
                                "file": fp["name"],
                                "page": page_idx,
                                "elapsed_sec": round(time.time() - t0, 3),
                                "rows": len(norm),
                            })
                        else:
                            st.session_state.logs.append({
                                "timestamp": datetime.now().isoformat(),
                                "status": "no_rows_or_parse_failed",
                                "file": fp["name"],
                                "page": page_idx,
                                "elapsed_sec": round(time.time() - t0, 3),
                            })

                    except Exception as e:
                        st.session_state.logs.append({
                            "timestamp": datetime.now().isoformat(),
                            "status": "error",
                            "file": fp["name"],
                            "page": page_idx,
                            "detail": str(e),
                        })

                    completed += 1
                    prog.progress(min(1.0, completed / total_tasks))

            else:
                status.text(f"Processing: {fp['name']}  |  {completed+1}/{total_tasks}")

                t0 = time.time()
                try:
                    img = Image.open(fp["file"])
                    pre = preprocess_image(img, contrast=contrast, sharpen=sharpen, binarize=binarize)

                    resp = model.generate_content([prompt, pre])
                    raw = getattr(resp, "text", "") or ""
                    rows = safe_json_extract(raw)

                    if rows is None and retry_json:
                        reprompt = prompt + "\n\nã€å†å‡ºåŠ›æŒ‡ç¤ºã€‘å¿…ãšJSONé…åˆ—ã®ã¿ã‚’è¿”ã™ã€‚æ–‡å­—åˆ—èª¬æ˜ã¯ç¦æ­¢ã€‚"
                        resp2 = model.generate_content([reprompt, pre])
                        raw2 = getattr(resp2, "text", "") or ""
                        rows = safe_json_extract(raw2)
                        if show_raw:
                            st.write(f"RAW (retry) {fp['name']}:")
                            st.code(raw2)

                    if show_raw:
                        st.write(f"RAW {fp['name']}:")
                        st.code(raw)

                    meta = {"å…ƒãƒ•ã‚¡ã‚¤ãƒ«": fp["name"], "ãƒšãƒ¼ã‚¸": ""}
                    norm = normalize_rows(rows, meta=meta)
                    if norm:
                        results_all.extend(norm)
                        st.session_state.logs.append({
                            "timestamp": datetime.now().isoformat(),
                            "status": "success",
                            "file": fp["name"],
                            "elapsed_sec": round(time.time() - t0, 3),
                            "rows": len(norm),
                        })
                    else:
                        st.session_state.logs.append({
                            "timestamp": datetime.now().isoformat(),
                            "status": "no_rows_or_parse_failed",
                            "file": fp["name"],
                            "elapsed_sec": round(time.time() - t0, 3),
                        })

                except Exception as e:
                    st.session_state.logs.append({
                        "timestamp": datetime.now().isoformat(),
                        "status": "error",
                        "file": fp["name"],
                        "detail": str(e),
                    })

                completed += 1
                prog.progress(min(1.0, completed / total_tasks))

        status.empty()
        prog.empty()

        if results_all:
            st.session_state.orders = pd.DataFrame(results_all)
            st.success(f"Done. Extracted {len(st.session_state.orders)} rows.")
        else:
            st.warning("è§£æçµæœãŒ0ä»¶ã§ã—ãŸã€‚FAXç”»åƒã®è§£åƒåº¦ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ»å‚¾ãã€ã¾ãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")

    # ---------------- Results / Exports ----------------
    if not st.session_state.orders.empty:
        st.divider()
        st.subheader("ğŸ§¾ Extracted Orders")

        edited = st.data_editor(
            st.session_state.orders,
            use_container_width=True,
            num_rows="dynamic",
        )

        c1, c2, c3 = st.columns(3)

        with c1:
            csv = edited.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "â¬‡ï¸ Download Orders CSV",
                data=csv,
                file_name=f"orders_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True,
            )

        with c2:
            if st.button("ğŸ§¾ Generate PDF", use_container_width=True):
                pdf_buf = create_simple_pdf(edited)
                st.download_button(
                    "â¬‡ï¸ Download PDF",
                    data=pdf_buf,
                    file_name="delivery_slip.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                )

        with c3:
            if st.button("ğŸ§¹ Clear Orders", use_container_width=True):
                st.session_state.orders = pd.DataFrame()
                st.rerun()

    # ---------------- Logs ----------------
    with st.expander("ğŸ“œ Logs / Diagnostics", expanded=False):
        log_df = pd.DataFrame(st.session_state.logs)
        if log_df.empty:
            st.caption("No logs yet.")
        else:
            st.dataframe(log_df, use_container_width=True, hide_index=True)
            log_csv = log_df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "â¬‡ï¸ Download Logs CSV",
                data=log_csv,
                file_name=f"analysis_logs_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True,
            )
            if st.button("Clear Logs"):
                st.session_state.logs = []
                st.rerun()